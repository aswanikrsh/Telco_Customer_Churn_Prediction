# -*- coding: utf-8 -*-
"""Telco_customer_churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V80Imu6MfWdMnyFN9BMwk-nGONOe6KAv

Problem Statement:


The **Telco Customer Churn dataset** aims to address the challenge of predicting whether a customer will churn (leave the service) based on their demographic, account, and service usage details.  


Objectives:


1. **Predict Churn**: Build a machine learning model to classify customers as "Churn" or "No Churn."
2. **Identify Key Drivers**: Analyze factors influencing customer churn, such as contract type, monthly charges, and tenure.
3. **Provide Insights**: Recommend strategies to reduce churn and improve customer retention.  

Target Variable:
- **`Churn`**: Yes/No (indicating if the customer left).
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

"""## Understand the Data"""

data=pd.read_csv('/content/WA_Fn-UseC_-Telco-Customer-Churn.csv')
df=pd.DataFrame(data)

df.head()

df.shape

df.columns

df.info()

df.isnull().sum()

df.describe()

"""## Visualization"""

df.hist(figsize=(10,8))

sns.countplot(data=df,x="Churn")

"""## Data Cleaning"""

df.drop_duplicates(inplace=True)

df.nunique()

df.head()

# df['gender']=df['gender'].replace(['Female','Male'],[0,1],inplace=True)

df['gender']=LabelEncoder().fit_transform(df['gender'])
df['customerID']=LabelEncoder().fit_transform(df['customerID'])
df['Partner']=LabelEncoder().fit_transform(df['Partner'])
df['Dependents']=LabelEncoder().fit_transform(df['Dependents'])
df['PhoneService']=LabelEncoder().fit_transform(df['PhoneService'])
df['MultipleLines']=LabelEncoder().fit_transform(df['MultipleLines'])
df['InternetService']=LabelEncoder().fit_transform(df['InternetService'])
df['OnlineSecurity']=LabelEncoder().fit_transform(df['OnlineSecurity'])
df['OnlineBackup']=LabelEncoder().fit_transform(df['OnlineBackup'])
df['DeviceProtection']=LabelEncoder().fit_transform(df['DeviceProtection'])
df['TechSupport']=LabelEncoder().fit_transform(df['TechSupport'])
df['StreamingTV']=LabelEncoder().fit_transform(df['StreamingTV'])
df['StreamingMovies']=LabelEncoder().fit_transform(df['StreamingMovies'])
df['Contract']=LabelEncoder().fit_transform(df['Contract'])
df['PaperlessBilling']=LabelEncoder().fit_transform(df['PaperlessBilling'])
df['PaymentMethod']=LabelEncoder().fit_transform(df['PaymentMethod'])
df['Churn']=LabelEncoder().fit_transform(df['Churn'])
df['TotalCharges']=LabelEncoder().fit_transform(df['TotalCharges'])

from imblearn.over_sampling import RandomOverSampler, SMOTE
import pandas as pd

X= df.drop('Churn',axis=1)
y= df['Churn']
ros=SMOTE()
X_resampled,y_resampled=ros.fit_resample(X,y)

df=pd.concat([X_resampled,y_resampled],axis=1)

plt.figure(figsize=(18,16))
sns.heatmap(df.corr(),annot=True)

price_corr = df.corr()['Churn'].sort_values(ascending=False)
price_corr = price_corr.drop('Churn')

sns.heatmap(price_corr.to_frame(), annot=True, fmt='.2f')
plt.title('Correlation between Churn and Other Features')
plt.show()

s=df.corr()['Churn']
s.sort_values(ascending=False)

df.drop('PaperlessBilling',axis=1,inplace=True)
df.drop('PaymentMethod',axis=1,inplace=True)
df.drop('TotalCharges',axis=1,inplace=True)
df.drop('SeniorCitizen',axis=1,inplace=True)
df.drop('customerID',axis=1,inplace=True)
df.drop('PhoneService',axis=1,inplace=True)
df.drop('MultipleLines',axis=1,inplace=True)
df.drop('StreamingTV',axis=1,inplace=True)
df.drop('StreamingMovies',axis=1,inplace=True)
df.drop('InternetService',axis=1,inplace=True)
df.drop('gender',axis=1,inplace=True)

sns.histplot(df['MonthlyCharges'],bins=30, kde=True)
plt.figure(figsize=(30,8))

df['MonthlyCharges'] = np.log1p(df['MonthlyCharges'])

sns.histplot(df['DeviceProtection'],bins=30, kde=True)
plt.figure(figsize=(30,8))

df['DeviceProtection'] = np.log1p(df['DeviceProtection'])

sns.histplot(df['Dependents'],bins=30, kde=True)
plt.figure(figsize=(30,8))

df['Dependents'] = np.log1p(df['Dependents'])

sns.histplot(df['Partner'],bins=30, kde=True)
plt.figure(figsize=(30,8))

df['Partner'] = np.log1p(df['Partner'])

sns.histplot(df['tenure'],bins=30, kde=True)
plt.figure(figsize=(30,8))

df['tenure'] = np.log1p(df['tenure'])

sns.histplot(df['OnlineSecurity'],bins=30, kde=True)
plt.figure(figsize=(30,8))

df['OnlineSecurity'] = np.log1p(df['OnlineSecurity'])

sns.histplot(df['OnlineBackup'],bins=30, kde=True)
plt.figure(figsize=(30,8))

df['OnlineBackup'] = np.log1p(df['OnlineBackup'])

sns.histplot(df['TechSupport'],bins=30, kde=True)
plt.figure(figsize=(30,8))

df['TechSupport'] = np.log1p(df['TechSupport'])

sns.histplot(df['Contract'],bins=30, kde=True)
plt.figure(figsize=(30,8))

df['Contract'] = np.log1p(df['Contract'])

sns.boxplot(df)

# def remove_outliers_iqr(df, exclude_column):
#     for col in df.columns:
#         if col == exclude_column:
#             continue
#         Q1 = df[col].quantile(0.25)
#         Q3 = df[col].quantile(0.75)
#         IQR = Q3 - Q1
#         lower_bound = Q1 - 1.5 * IQR
#         upper_bound = Q3 + 1.5 * IQR
#         df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
#     return df


# df= remove_outliers_iqr(df, exclude_column='Churn')

X=df[['tenure','OnlineSecurity','OnlineBackup','TechSupport','Contract','MonthlyCharges','DeviceProtection','Dependents','Partner']]
y=df['Churn']

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')

xgb_model.fit(X_train, y_train)

y_pred = xgb_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1}")

# from sklearn.linear_model import LogisticRegression

# model=LogisticRegression()

# model.fit(X_train,y_train)

# y_pred=model.predict(X_test)
# y_pred

# from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score
# accuaracy=accuracy_score(y_test,y_pred)
# precision=precision_score(y_test,y_pred)
# recall=recall_score(y_test,y_pred)
# f1=f1_score(y_test,y_pred)
# print(f"Accuracy: {accuaracy}")
# print(f"Precision: {precision}")
# print(f"Recall: {recall}")
# print(f"F1 Score: {f1}")